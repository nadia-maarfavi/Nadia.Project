{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SC_9AxXdYa1f"
      },
      "outputs": [],
      "source": [
        "# Seed value for reusability\n",
        "seed_value= 1\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2awlcRRdH-2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, KFold,  train_test_split, cross_validate\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
        "\n",
        "from numpy import mean, absolute, std\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, BaggingRegressor, HistGradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "from sklearn.metrics import mean_squared_error,r2_score, mean_absolute_error\n",
        "from math import sqrt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT_3kVJYetr_"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"........\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "df = shuffle(df)"
      ],
      "metadata": {
        "id": "eE51D0n4EALA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYZ58InYey4S"
      },
      "outputs": [],
      "source": [
        "df['Scores'] = np.log1p(df['Scores'])\n",
        "df['ProductionBudget'] = np.log1p(df['ProductionBudget'])\n",
        "df['OpeningTheater'] = np.log1p(df['OpeningTheater'])\n",
        "df['Difference'] = np.log1p(df['Difference'])\n",
        "df['Duration'] = np.log1p(df['Duration'])\n",
        "df['FaceNo'] = np.log1p(df['FaceNo'])\n",
        "df['Female'] = np.log1p(df['Female'])\n",
        "df['Male'] = np.log1p(df['Male'])\n",
        "df['AverageAge'] = np.log1p(df['AverageAge'])\n",
        "df['AvgFaceSize'] =np.log1p(df['AvgFaceSize'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTU49QF3ycsv"
      },
      "outputs": [],
      "source": [
        "# Control only features\n",
        "train_features = ['OpeningTheater','ProductionBudget','Scores', 'Follows','Action','Adventure','Biography','Comedy',\n",
        "'Crime','Documentary','Drama','Horror','Thriller',  'topStudio', 'PG-13','R','Not Rated','PG','NC-17','G', 'topMeters','topStars',\n",
        "'AwardStars']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAcwLBs5ezS3"
      },
      "outputs": [],
      "source": [
        "#Control + trailer content\n",
        "train_features = ['OpeningTheater','ProductionBudget','Scores', 'Follows','Action','Adventure','Biography','Comedy',\n",
        "'Crime','Documentary','Drama','Horror','Thriller',  'topStudio', 'PG-13','R','Not Rated','PG','NC-17','G', 'topMeters','topStars',\n",
        "'AwardStars',\n",
        "'Duration','Difference','RatioFaceNo','RatioMale','RatioFemale', 'FaceNo','Female','Male', 'RatioSad','RatioHappy', 'RatioFear',  'RatioAngry',\n",
        "'RatioSurprise',  'RatioDisgust',  'RatioNeutral','RatioAsian', 'RatioIndian', 'RatioBlack', 'RatioWhite', 'RatioMiddle','RatioHispanic',\n",
        "                    'AvgFaceSize', 'RatioFaceCoverage', 'AverageAge']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-CSNzu-e3bg"
      },
      "outputs": [],
      "source": [
        "X = df[train_features]\n",
        "y = df['OpeningGross'].values\n",
        "y = np.log1p(y)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnL7V36Re5q9"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=52)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc4R6rz2e7QF"
      },
      "outputs": [],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IiXAO8ke8qN"
      },
      "outputs": [],
      "source": [
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J58A1yuie-kz"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = seed_value\n",
        "\n",
        "# 5-fold CV\n",
        "kfolds = KFold(n_splits=5)\n",
        "# Define the helper function so that it can be reused\n",
        "def tune(objective):\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=500)\n",
        "\n",
        "    params = study.best_params\n",
        "    best_score = study.best_value\n",
        "    print(f\"Best score: {best_score}\\n\")\n",
        "    print(f\"Optimized parameters: {params}\\n\")\n",
        "    return params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QpkmRwlpfD4D"
      },
      "outputs": [],
      "source": [
        "##################\n",
        "# Extra Tree Regressor\n",
        "##################\n",
        "def ExTree_objective(trial):\n",
        "    _n_estimators = trial.suggest_int(\"n_estimators\", 1,1000)\n",
        "    _max_depth = trial.suggest_int(\"max_depth\", 2, 100)\n",
        "    _min_samp_split = trial.suggest_int(\"min_samples_split\", 2, 100)\n",
        "    _min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 2, 100)\n",
        "    _max_features = trial.suggest_int(\"max_features\", 2,23)\n",
        "\n",
        "    ExTree = ExtraTreesRegressor(\n",
        "        max_depth=_max_depth,\n",
        "        min_samples_split=_min_samp_split,\n",
        "        min_samples_leaf=_min_samples_leaf,\n",
        "        max_features=_max_features,\n",
        "        n_estimators=_n_estimators,\n",
        "        n_jobs=-1,\n",
        "        random_state=RANDOM_SEED,\n",
        "    )\n",
        "\n",
        "    score = cross_val_score(\n",
        "        ExTree, X_train, y_train, cv=kfolds, scoring=\"r2\"\n",
        "    ).mean()\n",
        "\n",
        "    return score\n",
        "\n",
        "ExTree_params = tune(ExTree_objective)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUytmhfohdnW"
      },
      "outputs": [],
      "source": [
        "ExtraTree = ExtraTreesRegressor(**ExTree_params, random_state=RANDOM_SEED)\n",
        "ExtraTree.fit(X_train, y_train)\n",
        "\n",
        "y_pred = ExtraTree.predict(X_test)\n",
        "print(r2_score(y_test,y_pred))\n",
        "print(mean_squared_error(y_test,y_pred))\n",
        "print(mean_absolute_error(y_test,y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjWes-30hhjM"
      },
      "outputs": [],
      "source": [
        "\n",
        "##################\n",
        "# Light Boosting\n",
        "##################\n",
        "def lgb_objective(trial):\n",
        "    _num_leaves = trial.suggest_int(\"num_leaves\", 2,100)\n",
        "    _learning_rate = trial.suggest_float(\"learning_rate\", 0.0001, 0.1)\n",
        "    _n_estimators = trial.suggest_int(\"n_estimators\", 1, 100)\n",
        "    _min_child_weight = trial.suggest_float(\"min_child_weight\",1,10)\n",
        "    _reg_alpha = trial.suggest_float('reg_alpha', 0.01, 10)\n",
        "    _reg_lambda = trial.suggest_float('reg_lambda', 0.01, 10)\n",
        "    _subsample = trial.suggest_float('subsample', 0.01, 1)\n",
        "\n",
        "    lgbr = LGBMRegressor(objective='regression',\n",
        "                             num_leaves=_num_leaves,\n",
        "                             learning_rate=_learning_rate,\n",
        "                             n_estimators=_n_estimators,\n",
        "                             min_child_weight=_min_child_weight,\n",
        "                             subsample=_subsample,\n",
        "                             reg_alpha=_reg_alpha,\n",
        "                             reg_lambda=_reg_lambda,\n",
        "                             random_state=RANDOM_SEED,\n",
        "    )\n",
        "    \n",
        "    score = cross_val_score(\n",
        "        lgbr, X_train, y_train, cv=kfolds, scoring=\"r2\"\n",
        "    ).mean()\n",
        "    return score\n",
        "\n",
        "lgb_params = tune(lgb_objective)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cKpzKEAkmrD"
      },
      "outputs": [],
      "source": [
        "lgbr = LGBMRegressor(objective='regression', random_state=RANDOM_SEED, **lgb_params)\n",
        "lgbr.fit(X_train, y_train)\n",
        "\n",
        "y_pred = lgbr.predict(X_test)\n",
        "print(r2_score(y_test,y_pred))\n",
        "print(mean_squared_error(y_test,y_pred))\n",
        "print(mean_absolute_error(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyAhhnAhoqAd"
      },
      "outputs": [],
      "source": [
        "##################\n",
        "# Random Forest\n",
        "##################\n",
        "def randomforest_objective(trial):\n",
        "    _n_estimators = trial.suggest_int(\"n_estimators\", 1, 1000)\n",
        "    _max_depth = trial.suggest_int(\"max_depth\", 1, 100)\n",
        "    _min_samp_split = trial.suggest_float(\"min_samples_split\", 0.0, 1.0)\n",
        "    _min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
        "    _max_features = trial.suggest_int(\"max_features\", 2, 23)\n",
        "\n",
        "    rf = RandomForestRegressor(\n",
        "        max_depth=10,\n",
        "        min_samples_split=_min_samp_split,\n",
        "        min_samples_leaf=_min_samples_leaf,\n",
        "        max_features=_max_features,\n",
        "        n_estimators=_n_estimators,\n",
        "        n_jobs=-1,\n",
        "        random_state=RANDOM_SEED,\n",
        "    )\n",
        "\n",
        "    score = cross_val_score(\n",
        "        rf, X_train, y_train, cv=kfolds, scoring=\"r2\"\n",
        "    ).mean()\n",
        "\n",
        "    return score\n",
        "\n",
        "randomforest_params = tune(randomforest_objective)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INIIrO_FovyZ"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestRegressor(n_jobs=-1, random_state=RANDOM_SEED, **randomforest_params)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "print(r2_score(y_test,y_pred))\n",
        "print(mean_squared_error(y_test,y_pred))\n",
        "print(mean_absolute_error(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPlATvK4ppEN"
      },
      "outputs": [],
      "source": [
        "##################\n",
        "# Bagging Regressor\n",
        "##################\n",
        "def Bagging_objective(trial):\n",
        "    _n_estimators = trial.suggest_int(\"n_estimators\", 1, 1000)\n",
        "    _max_samples= trial.suggest_int(\"max_samples\", 1, 300)\n",
        "    _max_features = trial.suggest_int(\"max_features\", 1, 23)\n",
        "\n",
        "    Bagging = BaggingRegressor(\n",
        "        max_samples=_max_samples,\n",
        "        max_features=_max_features,\n",
        "        n_estimators=_n_estimators,\n",
        "        n_jobs=-1,\n",
        "        random_state=RANDOM_SEED,\n",
        "    )\n",
        "\n",
        "    score = cross_val_score(\n",
        "        Bagging, X_train, y_train, cv=kfolds, scoring=\"r2\"\n",
        "    ).mean()\n",
        "\n",
        "    return score\n",
        "\n",
        "Bagging_params = tune(Bagging_objective)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgJ_qTT1q6i8"
      },
      "outputs": [],
      "source": [
        "Bagging = BaggingRegressor(n_jobs=-1, random_state=RANDOM_SEED, **Bagging_params)\n",
        "Bagging.fit(X_train, y_train)\n",
        "\n",
        "y_pred = Bagging.predict(X_test)\n",
        "print(r2_score(y_test,y_pred))\n",
        "print(mean_squared_error(y_test,y_pred))\n",
        "print(mean_absolute_error(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYx1k023rxtp"
      },
      "outputs": [],
      "source": [
        "##################\n",
        "# Hist Gradient Boosting\n",
        "##################\n",
        "def gbr_objective(trial):\n",
        "    _learning_rate = trial.suggest_float(\"learning_rate\", 0.0001, 0.1)\n",
        "    _max_depth = trial.suggest_int(\"max_depth\", 1,100)\n",
        "    _min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 2, 100)\n",
        "\n",
        "    _max_leaf_nodes = trial.suggest_int(\"max_leaf_nodes\", 2,100)\n",
        "    _max_bins = trial.suggest_int(\"max_bins\",10,255)\n",
        "\n",
        "    gbr = HistGradientBoostingRegressor(\n",
        "        learning_rate=_learning_rate,\n",
        "        max_depth=_max_depth, \n",
        "        min_samples_leaf=_min_samples_leaf,\n",
        "        max_leaf_nodes = _max_leaf_nodes,\n",
        "        random_state=RANDOM_SEED,\n",
        "    )\n",
        "\n",
        "    score = cross_val_score(\n",
        "        gbr, X_train, y_train, cv=kfolds, scoring=\"r2\"\n",
        "    ).mean()\n",
        "\n",
        "    return score\n",
        "\n",
        "gbr_params = tune(gbr_objective)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_fvdAtBCtCo"
      },
      "outputs": [],
      "source": [
        "HistGBR = HistGradientBoostingRegressor(random_state=RANDOM_SEED, **gbr_params)\n",
        "HistGBR.fit(X_train, y_train)\n",
        "\n",
        "y_pred = HistGBR.predict(X_test)\n",
        "print(r2_score(y_test,y_pred))\n",
        "print(mean_squared_error(y_test,y_pred))\n",
        "print(mean_absolute_error(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCxcP25WuQCG"
      },
      "outputs": [],
      "source": [
        "##################\n",
        "# XGB Boosting\n",
        "##################\n",
        "def xgb_objective(trial):\n",
        "    _n_estimators = trial.suggest_int(\"n_estimators\", 1,1000)\n",
        "    _max_depth = trial.suggest_int(\"max_depth\", 2, 100)\n",
        "    _learning_rate = trial.suggest_float(\"learning_rate\", 0.0001, 0.1)\n",
        "    _gamma = trial.suggest_float(\"gamma\", 0.0001, 100)\n",
        "    _min_child_weight = trial.suggest_float(\"min_child_weight\", 0.1, 100)\n",
        "    _subsample = trial.suggest_float('subsample', 0.0001, 1)\n",
        "    _reg_alpha = trial.suggest_float('reg_alpha',0.0001, 100)\n",
        "    _reg_lambda = trial.suggest_float('reg_lambda', 0.0001, 100)\n",
        "\n",
        "    \n",
        "    xgbr = xgb.XGBRegressor(\n",
        "        n_estimators=_n_estimators,\n",
        "        max_depth=_max_depth, \n",
        "        learning_rate=_learning_rate,\n",
        "        gamma=_gamma,\n",
        "        min_child_weight=_min_child_weight,\n",
        "        subsample=_subsample,\n",
        "        reg_alpha=_reg_alpha,\n",
        "        reg_lambda=_reg_lambda,\n",
        "        random_state=RANDOM_SEED,\n",
        "    )\n",
        "    \n",
        "    score = cross_val_score(\n",
        "        xgbr, X_train, y_train, cv=kfolds, scoring=\"r2\"\n",
        "    ).mean()\n",
        "    return score\n",
        "\n",
        "xgb_params = tune(xgb_objective)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kes9CcguWA4"
      },
      "outputs": [],
      "source": [
        "xgbr = xgb.XGBRegressor(random_state=RANDOM_SEED, **xgb_params)\n",
        "xgbr.fit(X_train, y_train)\n",
        "\n",
        "y_pred = xgbr.predict(X_test)\n",
        "print(r2_score(y_test,y_pred))\n",
        "print(mean_squared_error(y_test,y_pred))\n",
        "print(mean_absolute_error(y_test,y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "13gdvBDnjOosj7nTAl-MZaKUJbwtZiutT",
      "authorship_tag": "ABX9TyPEhZALWOVDgQ9Ue7g9uLJh"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}